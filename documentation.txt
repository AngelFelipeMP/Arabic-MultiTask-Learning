#### Download code and data
clone code repo 
    -> git clone https://github.com/AngelFelipeMP/Arabic-MultiTask-Learning
    -> OR git clone https://AngelFelipeMP:<GITTOKEN>@github.com/AngelFelipeMP/Arabic-MultiTask-Learning
cd Arabic-MultiTask-Learning
clone data repo
    -> git clone https://github.com/AngelFelipeMP/arabic-data-mtl
    -> OR git clone https://AngelFelipeMP:<GITTOKEN>@github.com/AngelFelipeMP/arabic-data-mtl
git configuration
    -> git config --global user.email "<EMAIL>"
    -> git config --global user.name "<NAME>"
cd mtl-baseline
create folder: data, logs inside mtl-baseline
    -> mkdir data
    -> mkdir logs
cd ..
create cpu and gpu conde envs from .yml file (root of repo)
    -> conda env create -f environment.yml
    -> conda env create -f environment_gpu.yml

#### Data Exploration
inside: Arabic-MultiTask-Learning/
run 1: python data_exploration.py
run 2: python token_analyse.py

#### RUN MTL-baseline
## Outline
    -> run get_data.py (Preprocess data)
    -> set parameters in config files in mtl-baseline/configs
    -> delet all files in mtl-baseline/logs
    -> create a tmux session
    -> run train-test.py/cross-validation.py
    -> run analyses.py (TOP MODELS)

## Process data
inside: Arabic-MultiTask-Learning/mtl-baseline/
run 1: cd mtl-baseline
run 2: python get_data.py

## Preper conf. files
set parameters in config files
    -> mtl-baseline/configs/EA0_information_config.json
        + experiment (e.g. EA0)
        + device
        + folds_number
        + language
    -> mtl-baseline/configs/EA0_parameter_config.json
        + max_len
        + batch_size
        + epochs
        + learning_rate
        + transfomer_model

## Run experiments
inside: Arabic-MultiTask-Learning/mtl-baseline/MultiTask-Learning-for-Toxic-Language-Classification/machamp
run 1: cd MultiTask-Learning-for-Toxic-Language-Classification/machamp
run 2: (e.g.:) python ../scripts/train-test.py --information_config EA0/EA0_information_config.json --debug
Delete all files in machamp/logs folder
run 3: (e.g.:) python ../scripts/train-test.py --information_config EA0/EA0_information_config.json
OR 
run 2: (e.g.:) python ../scripts/cross-validation.py --information_config EAC0/EAC0_information_config.json --debug
Delete all files in machamp/logs folder
run 3: (e.g.:) python ../scripts/cross-validation.py --information_config EAC0/EAC0_information_config.json

## Get confidence interval
inside: Arabic-MultiTask-Learning/mtl-baseline/MultiTask-Learning-for-Toxic-Language-Classification/machamp
run: (e.g.:) python ../scripts/analyses.py --experiment_results <EXPERIMENT_FOLDER> (e.g: EA0)

#### OBS 
1) run experiments on mtl-baseline
    -> we must have stl config files in mtl-baseline/configs/E.../ (e.g. mtl-baseline/configs/E1/)

#### RUN MTL-model
inside: cd /home/adepau/repos/Arabic-MultiTask-Learning/mtl-model/Multi-Task-Learning-advanced-algorithms

## Outline
    -> run get_data.py (Preprocess data) -> ##COMMENT: I NEED IT 
    -> set parameters in config files in mtl-model/configs
    -> delet all files in mtl-model/logs
    -> create a tmux session
    -> run train-test.py/cross-validation.py
    -> run results_pos_process.py (TOP MODELS)

## Preper conf. files
set parameters in config files
    -> mtl-model/config.py
        + max_len
        + batch_size
        + epochs
        + learning_rate
        + transfomer_model
        + device
        + language

## Run experiments
# analysis - > run 1: python analysis.py
# train-test -> run 2: python train_test.py
# cross_validation -> run 3: python cross_validation.py
# table top results -> run 4: python results_pos_process.py