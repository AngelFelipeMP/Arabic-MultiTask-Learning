# Arabic Sexism, Offensive Language, and Hate Speech Detection

![ScreenShot](image/LLM_robot.png)

## Overview

This repository houses the research and development efforts focused on the creation of a sophisticated Large Language Model specialized in the identification and categorization of Arabic text data related to sexism, offensive language, and hate speech. The primary objective is to enhance the accuracy and efficiency of detection for these social media perils by adopting a multitask learning approach.

## Project Goal

The goal of this project is to design and train a single Large Language Model using multitask learning techniques to concurrently address three distinct, yet related, natural language processing tasks:

1. **Sexism Detection**
2. **Offensive Language Identification**
3. **Hate Speech Recognition**

By intertwining the learning processes for these tasks within a unified model, we aim to achieve superior performance as compared to three individual models each handling a single task.

## Multitask Learning Strategy

Our methodology involves leveraging shared representations and joint training to enable the model to generalize better across all three tasks. This is premised on the hypothesis that these tasks share underlying linguistic and contextual features that a multitask model can learn and exploit more effectively than separate models dedicated to each task.

## Expected Outcomes

We anticipate that this multitask learning model will not only streamline the detection process but also outperform the traditional single-task models in terms of detection rates. This could pave the way for more robust and efficient tools for monitoring and mitigating abusive language on Arabic-speaking social media platforms.

## Contact

For questions, collaborations, or contributions, please feel free to open an issue or submit a pull request.

## License

 Apache 2.0
